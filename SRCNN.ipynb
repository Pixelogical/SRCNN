{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pixelogical/SRCNN/blob/main/SRCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAOVe65bPcUL"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        " \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Conv2D, Activation, Input\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        " \n",
        "from IPython.display import display\n",
        "import cv2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2iBkzniBwWf"
      },
      "source": [
        "##Load dataset from google_drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1Jl1wshl4Li",
        "outputId": "37277023-c5b7-4d63-b0e3-696b1503aec6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqvkmdoamKww"
      },
      "source": [
        "!rm -rf data\n",
        "!rm -rf dataset\n",
        "!rm -rf SCID\n",
        "!rm -rf SIQAD\n",
        "!rm -rf QACS"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwbYZVSSlvpc"
      },
      "source": [
        "!unzip \"/content/drive/MyDrive/Proposal/SCID.zip\" -d \"/content/SIQAD/\"\n",
        "# !cp /content/drive/MyDrive/ANN/Proposal/SCID/ -r /content/SCID\n",
        "# !cp /content/drive/MyDrive/ANN/Proposal/QACS/QACS/ORG/ -r /content/QACS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JShIHJklKVvN"
      },
      "source": [
        "##Create Patches from Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXxDGrAyKK62"
      },
      "source": [
        "def create_patch(img,crop_size_lr):\n",
        "  numx = int(img.shape[0] / crop_size_lr)\n",
        "  numy = int(img.shape[1] / crop_size_lr)\n",
        "  patches = []\n",
        "  for i in range(0, numx):\n",
        "    startx = i * crop_size_lr\n",
        "    endx = (i * crop_size_lr) + crop_size_lr\n",
        "    for j in range(0, numy):\n",
        "      starty = j * crop_size_lr\n",
        "      endy = (j * crop_size_lr) + crop_size_lr\n",
        "      if len(img.shape) == 3:\n",
        "        crop_lr = img[startx:endx, starty:endy,:] \n",
        "      else:\n",
        "        crop_lr = img[startx:endx, starty:endy] \n",
        "      patches.append(crop_lr)\n",
        "  return patches "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXEqt5cxAIIQ"
      },
      "source": [
        "crop_size_lr = 16\n",
        "dest_dir = 'data/train'\n",
        "train_data = []\n",
        "train_label = []\n",
        "dataset_paths = ['QACS','SCID']\n",
        " \n",
        "if not os.path.exists(dest_dir):\n",
        "  os.makedirs(dest_dir)\n",
        " \n",
        "nimg = 0\n",
        "for dataset_path in dataset_paths:\n",
        "  for n in os.listdir(dataset_path):\n",
        "    if 'bmp' not in n and 'jpg' not in n and 'png' not in n:\n",
        "      continue\n",
        "    img = cv2.imread(os.path.join(dataset_path,n))\n",
        "    img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
        "    y, _, _ = cv2.split(img_yuv)\n",
        "\n",
        "    # creating LR from Label\n",
        "    small = cv2.resize(y,     (y.shape[1]//2, y.shape[0]//2), interpolation=cv2.INTER_CUBIC)\n",
        "    big = cv2.resize(small,   (y.shape[1],    y.shape[0]),    interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    #cropping into pieces:\n",
        "    y_patches = create_patch(y,crop_size_lr)\n",
        "    for patch in y_patches:\n",
        "      train_label.append(patch)\n",
        "    big_patches = create_patch(big,crop_size_lr)\n",
        "    for patch in big_patches:\n",
        "      train_data.append(patch)\n",
        " \n",
        "train_label = np.float32(train_label)\n",
        "train_data = np.float32(train_data)\n",
        "train_data = train_data.reshape((train_data.shape[0],crop_size_lr,crop_size_lr,1))\n",
        "train_label = train_label.reshape((train_label.shape[0],crop_size_lr,crop_size_lr,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzkhKm9qWxN_",
        "outputId": "5b803f4c-2547-43d3-839b-5d4d881d1f44"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(281160, 16, 16, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay120fO2c9RZ",
        "outputId": "6891a322-0076-408a-a2ba-b75fd4ec796c"
      },
      "source": [
        "from PIL import Image\n",
        "jpeg = [[16,11,10,16,24,40,51,111],\n",
        "[12,12,14,19,26,58,60,55],\n",
        "[14,13,16,24,40,57,69,56],\n",
        "[14,17,22,29,51,87,80,62],\n",
        "[18,22,37,56,68,109,103,77],\n",
        "[24,35,55,64,81,104,113,92],\n",
        "[49,64,78,87,103,121,120,101],\n",
        "[72,92,95,98,112,100,103,99]]\n",
        " \n",
        " \n",
        "prop = [[16,10,10,10,10,10,10,10],\n",
        "[10,11,11,11,11,11,11,11],\n",
        "[10,11,12,12,12,12,12,12],\n",
        "[10,11,12,14,14,14,14,14],\n",
        "[10,11,12,14,28,28,28,28],\n",
        "[10,11,12,14,28,56,56,56],\n",
        "[10,11,12,14,28,56,106,106],\n",
        "[10,11,12,14,28,56,106,121]]\n",
        "\n",
        "# ******** Select Prop or Jpeg ********\n",
        "quantization = prop\n",
        "# ******** ******************* ********\n",
        "\n",
        "prop= np.float32(quantization)\n",
        "prop = Image.fromarray(prop)\n",
        "prop = prop.resize((16, 16), Image.BILINEAR)\n",
        "# prop.shape\n",
        "prop = np.asarray(prop)\n",
        "prop = prop.reshape((1,16,16,1))\n",
        "\n",
        "prop.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 16, 16, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6aFltURdCyD"
      },
      "source": [
        "def dct_2d(feature_map,norm=None):\n",
        "    X1 = tf.signal.dct(feature_map, type=2, norm=norm)\n",
        "    X1_t = tf.transpose(X1, perm=[0, 1, 3, 2])\n",
        "    X2 = tf.signal.dct(X1_t, type=2, norm=norm)\n",
        "    X2_t = tf.transpose(X2, perm=[0, 1, 3, 2])\n",
        "    return X2_t\n",
        " \n",
        "def idct_2d(feature_map,norm=None):\n",
        "    X1 = tf.signal.idct(feature_map, type=2, norm=norm)\n",
        "    X1_t = tf.transpose(X1, perm=[0, 1, 3, 2])\n",
        "    X2 = tf.signal.idct(X1_t, type=2, norm=norm)\n",
        "    X2_t = tf.transpose(X2, perm=[0, 1, 3, 2])\n",
        "    return X2_t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c7kbltldH0_"
      },
      "source": [
        "def myloss(y_true,y_pred):\n",
        "  # quantization = np.load(\"quantization_34_34.npy\")\n",
        "  # # quantization = jpeg\n",
        " \n",
        "  sr = dct_2d(y_pred)\n",
        "  sr = tf.divide(sr,prop)\n",
        "\n",
        "  hr = dct_2d(y_true)\n",
        "  hr = tf.divide(hr,prop)\n",
        " \n",
        " \n",
        "  # hr = y_true\n",
        "  # sr = y_pred\n",
        "\n",
        "  ee = tf.square(hr-sr)\n",
        "  ee = tf.reduce_mean(ee)\n",
        "  return ee"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFtTe8hwOj7r",
        "outputId": "f0ae59e4-7c6b-4bad-fb11-7af80b3da78e"
      },
      "source": [
        "# define model type\n",
        "SRCNN = Sequential()\n",
        " \n",
        "# add model layers\n",
        "SRCNN.add(Conv2D(filters=64, kernel_size = (9, 9), kernel_initializer='glorot_uniform',\n",
        "                  activation='relu', padding='same', use_bias=True, input_shape=(16,16, 1)))\n",
        "SRCNN.add(Conv2D(filters=32, kernel_size = (1, 1), kernel_initializer='glorot_uniform',\n",
        "                  activation='relu', padding='same', use_bias=True))\n",
        "SRCNN.add(Conv2D(filters=1, kernel_size = (5, 5), kernel_initializer='glorot_uniform',\n",
        "                  activation='linear', padding='same', use_bias=True))\n",
        " \n",
        "# define optimizer\n",
        "adam = Adam(learning_rate=0.0003)\n",
        " \n",
        "SRCNN.summary()\n",
        " \n",
        "# compile model\n",
        "SRCNN.compile(optimizer=adam, loss='mse')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_21 (Conv2D)           (None, 16, 16, 64)        5248      \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 16, 16, 32)        2080      \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 16, 16, 1)         801       \n",
            "=================================================================\n",
            "Total params: 8,129\n",
            "Trainable params: 8,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DKK_YFGTC0L",
        "outputId": "0ffcbc12-5eb0-4186-bdc9-476b63b61578"
      },
      "source": [
        "epochs = 1000\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, mode='min', restore_best_weights=True,verbose=True)\n",
        "\n",
        "history = SRCNN.fit(\n",
        "    train_data,train_label, epochs=epochs, batch_size=128, validation_split = 0.2, callbacks=[callback]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 1605.6280 - val_loss: 383.0120\n",
            "Epoch 2/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 487.4034 - val_loss: 370.1242\n",
            "Epoch 3/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 467.0312 - val_loss: 364.9180\n",
            "Epoch 4/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 457.0021 - val_loss: 360.2322\n",
            "Epoch 5/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 447.0396 - val_loss: 367.6056\n",
            "Epoch 6/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 441.7519 - val_loss: 355.8019\n",
            "Epoch 7/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 433.2565 - val_loss: 352.1023\n",
            "Epoch 8/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 431.1770 - val_loss: 350.0254\n",
            "Epoch 9/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 427.7481 - val_loss: 348.7015\n",
            "Epoch 10/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 424.5017 - val_loss: 345.3714\n",
            "Epoch 11/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 423.6145 - val_loss: 347.2368\n",
            "Epoch 12/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 421.6171 - val_loss: 345.2106\n",
            "Epoch 13/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 419.7131 - val_loss: 344.4861\n",
            "Epoch 14/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 419.7098 - val_loss: 343.2075\n",
            "Epoch 15/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 414.3288 - val_loss: 341.1484\n",
            "Epoch 16/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 417.9544 - val_loss: 345.2374\n",
            "Epoch 17/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 413.1208 - val_loss: 344.0323\n",
            "Epoch 18/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 411.3756 - val_loss: 342.5156\n",
            "Epoch 19/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 411.1007 - val_loss: 340.1892\n",
            "Epoch 20/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 410.9746 - val_loss: 340.4389\n",
            "Epoch 21/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 412.1343 - val_loss: 343.2054\n",
            "Epoch 22/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 409.1573 - val_loss: 342.2010\n",
            "Epoch 23/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 404.5391 - val_loss: 337.5958\n",
            "Epoch 24/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 407.3697 - val_loss: 337.6535\n",
            "Epoch 25/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 405.2606 - val_loss: 339.7976\n",
            "Epoch 26/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 408.3102 - val_loss: 348.8237\n",
            "Epoch 27/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 406.6155 - val_loss: 338.5483\n",
            "Epoch 28/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 405.8121 - val_loss: 346.0837\n",
            "Epoch 29/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 405.8664 - val_loss: 337.6315\n",
            "Epoch 30/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 403.3113 - val_loss: 337.2509\n",
            "Epoch 31/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 404.3315 - val_loss: 338.6790\n",
            "Epoch 32/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 403.8286 - val_loss: 336.9690\n",
            "Epoch 33/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 400.9514 - val_loss: 338.2213\n",
            "Epoch 34/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 402.4852 - val_loss: 335.5284\n",
            "Epoch 35/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 398.8435 - val_loss: 339.5089\n",
            "Epoch 36/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 400.9927 - val_loss: 335.2715\n",
            "Epoch 37/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 403.4191 - val_loss: 336.5469\n",
            "Epoch 38/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 401.6864 - val_loss: 334.9413\n",
            "Epoch 39/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 399.6578 - val_loss: 335.9703\n",
            "Epoch 40/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 401.8648 - val_loss: 339.5434\n",
            "Epoch 41/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 397.4545 - val_loss: 332.2249\n",
            "Epoch 42/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 397.7465 - val_loss: 335.8852\n",
            "Epoch 43/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 399.1912 - val_loss: 335.0431\n",
            "Epoch 44/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 398.5191 - val_loss: 331.8616\n",
            "Epoch 45/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 396.6501 - val_loss: 336.0469\n",
            "Epoch 46/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 395.5601 - val_loss: 333.2831\n",
            "Epoch 47/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 394.9844 - val_loss: 333.1411\n",
            "Epoch 48/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 398.1683 - val_loss: 332.8474\n",
            "Epoch 49/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 395.8429 - val_loss: 332.5601\n",
            "Epoch 50/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 397.8900 - val_loss: 333.4940\n",
            "Epoch 51/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 397.6251 - val_loss: 331.6905\n",
            "Epoch 52/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 394.9084 - val_loss: 340.5428\n",
            "Epoch 53/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 397.6260 - val_loss: 331.7907\n",
            "Epoch 54/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 394.9850 - val_loss: 333.1234\n",
            "Epoch 55/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 391.2183 - val_loss: 332.5540\n",
            "Epoch 56/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 396.5121 - val_loss: 332.8565\n",
            "Epoch 57/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 396.5018 - val_loss: 333.0736\n",
            "Epoch 58/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 394.2504 - val_loss: 330.6157\n",
            "Epoch 59/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 395.0066 - val_loss: 332.6894\n",
            "Epoch 60/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 391.3456 - val_loss: 334.2523\n",
            "Epoch 61/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 396.0347 - val_loss: 330.6544\n",
            "Epoch 62/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 393.7905 - val_loss: 335.3369\n",
            "Epoch 63/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 394.3699 - val_loss: 334.4959\n",
            "Epoch 64/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 392.8349 - val_loss: 330.7308\n",
            "Epoch 65/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 393.5713 - val_loss: 331.9111\n",
            "Epoch 66/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 394.5448 - val_loss: 331.5795\n",
            "Epoch 67/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 396.1474 - val_loss: 329.4164\n",
            "Epoch 68/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 393.4481 - val_loss: 333.2075\n",
            "Epoch 69/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 392.5661 - val_loss: 330.7838\n",
            "Epoch 70/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 397.7876 - val_loss: 328.3183\n",
            "Epoch 71/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 393.6928 - val_loss: 329.3570\n",
            "Epoch 72/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 392.6650 - val_loss: 330.3312\n",
            "Epoch 73/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 388.3972 - val_loss: 329.9857\n",
            "Epoch 74/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 391.6288 - val_loss: 328.7822\n",
            "Epoch 75/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 394.6887 - val_loss: 329.6955\n",
            "Epoch 76/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 392.2249 - val_loss: 328.4162\n",
            "Epoch 77/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 391.6437 - val_loss: 330.6959\n",
            "Epoch 78/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 393.7068 - val_loss: 327.9947\n",
            "Epoch 79/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 392.1395 - val_loss: 327.6787\n",
            "Epoch 80/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 391.5592 - val_loss: 329.9278\n",
            "Epoch 81/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 391.3009 - val_loss: 326.6001\n",
            "Epoch 82/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 390.6777 - val_loss: 327.3554\n",
            "Epoch 83/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 392.2153 - val_loss: 329.6407\n",
            "Epoch 84/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 389.6352 - val_loss: 329.3490\n",
            "Epoch 85/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 390.3338 - val_loss: 327.7670\n",
            "Epoch 86/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 390.2665 - val_loss: 329.7573\n",
            "Epoch 87/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 388.7249 - val_loss: 330.3238\n",
            "Epoch 88/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 392.2849 - val_loss: 326.4525\n",
            "Epoch 89/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 394.5371 - val_loss: 331.2197\n",
            "Epoch 90/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 391.2485 - val_loss: 329.4372\n",
            "Epoch 91/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 388.3469 - val_loss: 328.7171\n",
            "Epoch 92/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 386.4493 - val_loss: 329.1849\n",
            "Epoch 93/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 388.5679 - val_loss: 330.0030\n",
            "Epoch 94/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 388.1473 - val_loss: 329.0648\n",
            "Epoch 95/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 388.7879 - val_loss: 328.1640\n",
            "Epoch 96/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 387.2750 - val_loss: 325.1075\n",
            "Epoch 97/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 389.4642 - val_loss: 326.0471\n",
            "Epoch 98/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 389.0599 - val_loss: 332.4119\n",
            "Epoch 99/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 387.2688 - val_loss: 330.4435\n",
            "Epoch 100/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 388.8124 - val_loss: 327.5571\n",
            "Epoch 101/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 388.6282 - val_loss: 330.6076\n",
            "Epoch 102/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 389.4411 - val_loss: 326.5608\n",
            "Epoch 103/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 386.1176 - val_loss: 327.3028\n",
            "Epoch 104/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 386.6151 - val_loss: 327.9674\n",
            "Epoch 105/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 388.7016 - val_loss: 327.0314\n",
            "Epoch 106/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 386.7239 - val_loss: 325.0067\n",
            "Epoch 107/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 389.5946 - val_loss: 329.3940\n",
            "Epoch 108/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 385.6851 - val_loss: 325.6473\n",
            "Epoch 109/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 384.3111 - val_loss: 329.8586\n",
            "Epoch 110/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 386.0776 - val_loss: 329.7982\n",
            "Epoch 111/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 386.7786 - val_loss: 326.9384\n",
            "Epoch 112/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 385.9533 - val_loss: 325.3805\n",
            "Epoch 113/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 384.4715 - val_loss: 327.9923\n",
            "Epoch 114/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 386.0156 - val_loss: 324.4061\n",
            "Epoch 115/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 386.2822 - val_loss: 328.7848\n",
            "Epoch 116/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 385.0317 - val_loss: 327.1227\n",
            "Epoch 117/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 386.9107 - val_loss: 327.0265\n",
            "Epoch 118/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 381.1618 - val_loss: 326.6711\n",
            "Epoch 119/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 387.0918 - val_loss: 327.8045\n",
            "Epoch 120/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 383.9431 - val_loss: 326.3622\n",
            "Epoch 121/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 387.5216 - val_loss: 326.4402\n",
            "Epoch 122/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 385.3124 - val_loss: 325.6612\n",
            "Epoch 123/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 383.3320 - val_loss: 325.2234\n",
            "Epoch 124/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 382.4446 - val_loss: 325.1950\n",
            "Epoch 125/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 384.8022 - val_loss: 328.6758\n",
            "Epoch 126/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 384.7654 - val_loss: 324.5935\n",
            "Epoch 127/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 384.9841 - val_loss: 328.8565\n",
            "Epoch 128/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 385.0245 - val_loss: 327.4515\n",
            "Epoch 129/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 386.8185 - val_loss: 328.2236\n",
            "Epoch 130/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 383.9639 - val_loss: 328.4889\n",
            "Epoch 131/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 382.2297 - val_loss: 322.5340\n",
            "Epoch 132/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 383.3611 - val_loss: 327.3841\n",
            "Epoch 133/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 385.1300 - val_loss: 327.1661\n",
            "Epoch 134/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 383.8314 - val_loss: 328.4811\n",
            "Epoch 135/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 385.5132 - val_loss: 322.9803\n",
            "Epoch 136/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 383.5706 - val_loss: 326.8893\n",
            "Epoch 137/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 383.0735 - val_loss: 328.7958\n",
            "Epoch 138/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 380.4348 - val_loss: 331.2110\n",
            "Epoch 139/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 381.5537 - val_loss: 325.1819\n",
            "Epoch 140/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 384.9324 - val_loss: 326.6152\n",
            "Epoch 141/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 383.5910 - val_loss: 325.3138\n",
            "Epoch 142/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 382.8209 - val_loss: 323.6775\n",
            "Epoch 143/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 382.4992 - val_loss: 326.6041\n",
            "Epoch 144/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 382.6568 - val_loss: 325.3116\n",
            "Epoch 145/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 383.5582 - val_loss: 325.0111\n",
            "Epoch 146/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 381.2495 - val_loss: 324.7609\n",
            "Epoch 147/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 381.7794 - val_loss: 332.7517\n",
            "Epoch 148/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 383.9163 - val_loss: 325.6652\n",
            "Epoch 149/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 382.5579 - val_loss: 326.3954\n",
            "Epoch 150/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 382.5306 - val_loss: 324.8559\n",
            "Epoch 151/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 383.3091 - val_loss: 323.4917\n",
            "Epoch 152/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 383.4023 - val_loss: 325.8494\n",
            "Epoch 153/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 381.0953 - val_loss: 324.6243\n",
            "Epoch 154/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 384.1970 - val_loss: 327.8184\n",
            "Epoch 155/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 385.3111 - val_loss: 325.0422\n",
            "Epoch 156/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 381.8864 - val_loss: 327.3963\n",
            "Epoch 157/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 384.1718 - val_loss: 324.6640\n",
            "Epoch 158/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 380.4954 - val_loss: 326.6376\n",
            "Epoch 159/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 380.4975 - val_loss: 324.8309\n",
            "Epoch 160/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 381.1355 - val_loss: 323.9743\n",
            "Epoch 161/1000\n",
            "1758/1758 [==============================] - 9s 5ms/step - loss: 383.5313 - val_loss: 323.6631\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00161: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4bE1chaBiXk"
      },
      "source": [
        "Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a_ieKt2VgXX"
      },
      "source": [
        "# SRCNN.save('/content/drive/MyDrive/ANN/Proposal/SRCNN-SRSC/6/YCHFirst_Patched16All-1000EPOCH-MSE2.h5')\n",
        "# np.save('/content/drive/MyDrive/ANN/Proposal/SRCNN-SRSC/6/YCHFirst_Patched16All-1000EPOCH-MSE2.npy',history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwvWBT-GBk15"
      },
      "source": [
        "Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-LFPbKDmLW1"
      },
      "source": [
        "SRCNN = keras.models.load_model('/content/drive/MyDrive/ANN/Proposal/SRCNN-SRSC/5/Patched16All-100EPOCH-MSE.h5',compile=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSnVGga3-Dv5"
      },
      "source": [
        "##Single image test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "B7sfeRSfDsZz",
        "outputId": "9e8ad981-c4ec-40dd-fed5-fb8104ce34b8"
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        " \n",
        " \n",
        "img = cv2.imread(\"SIQAD/references/cim1.bmp\")\n",
        "img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
        "y, _, _ = cv2.split(img_yuv)\n",
        "\n",
        "# creating LR from Label\n",
        "small = cv2.resize(y,     (y.shape[1]//2, y.shape[0]//2), interpolation=cv2.INTER_CUBIC)\n",
        "big = cv2.resize(small,   (y.shape[1],    y.shape[0]),    interpolation=cv2.INTER_CUBIC)\n",
        "big_patches = create_patch(big,16)\n",
        "big_patches = np.uint16(big_patches)\n",
        "big_patches.shape\n",
        "x = MSE.predict(big_patches.reshape((big_patches.shape[0],big_patches.shape[1],big_patches.shape[2],1)))\n",
        "nx,ny = y.shape[0] // 16 , y.shape[1] // 16\n",
        "x[x > 255] = 255\n",
        "x[x < 0] = 0\n",
        "x = np.uint16(x).reshape((nx,ny,16,16))\n",
        "\n",
        "reconstruct = np.zeros((nx*16,ny*16))\n",
        "for i in range(nx):\n",
        "  for j in range(ny):\n",
        "    reconstruct[i*16:i*16 + 16,j*16:j*16+16] = x[i][j]\n",
        "plt.figure(figsize=(16,9))\n",
        "\n",
        "# reconstruct[reconstruct > 255] = 255\n",
        "print(reconstruct[322:324,74:95])\n",
        "plt.imshow(reconstruct[322:324,74:95])\n",
        "\n",
        "# f, axs = plt.subplots(1,3,figsize=(25,15))\n",
        "# axs[0].imshow(y,cmap='gray')\n",
        "# axs[1].imshow(big,cmap='gray')\n",
        "# axs[2].imshow(reconstruct,cmap='gray')\n",
        " \n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. 0. 0. 0. 9. 9. 7. 4. 6. 6. 0. 0. 0. 2. 3. 3. 4. 0. 1.]\n",
            " [8. 7. 2. 0. 0. 0. 2. 1. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 6.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdd443a02d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyxQqWGy-HhW"
      },
      "source": [
        "##Batch image test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QMPEahp-0bx"
      },
      "source": [
        "MSE = keras.models.load_model('/content/drive/MyDrive/ANN/Proposal/SRCNN-SRSC/6/YCHFirst_Patched16All-1000EPOCH-MSE.h5',compile=False)\n",
        "JPEG = keras.models.load_model('/content/drive/MyDrive/ANN/Proposal/SRCNN-SRSC/6/YCHFirst_Patched16All-1000EPOCH-JPEG.h5',compile=False)\n",
        "PROP = keras.models.load_model('/content/drive/MyDrive/ANN/Proposal/SRCNN-SRSC/6/YCHFirst_Patched16All-1000EPOCH-PROP.h5',compile=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6C6UXzTncFN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eea39a3f-0c99-4459-f268-205461a02daf"
      },
      "source": [
        "dataset_path = 'SIQAD/references'\n",
        "version = '6'\n",
        "\n",
        "if not os.path.exists(version):\n",
        "  os.makedirs(version)\n",
        "\n",
        " \n",
        "\n",
        "for n in os.listdir(dataset_path):\n",
        "  if 'bmp' not in n and 'jpg' not in n and 'png' not in n:\n",
        "    continue\n",
        "  img = cv2.imread(os.path.join(dataset_path,n))\n",
        "  img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
        "  y, _, _ = cv2.split(img_yuv)\n",
        "\n",
        "  # creating LR from Label\n",
        "  small = cv2.resize(y,     (y.shape[1]//2, y.shape[0]//2), interpolation=cv2.INTER_CUBIC)\n",
        "  big = cv2.resize(small,   (y.shape[1],    y.shape[0]),    interpolation=cv2.INTER_CUBIC)\n",
        "  \n",
        "  big_patches = create_patch(big,16)\n",
        "  big_patches = np.uint16(big_patches)\n",
        "  mse = MSE.predict(big_patches.reshape((big_patches.shape[0],big_patches.shape[1],big_patches.shape[2],1)))\n",
        "  jpeg = JPEG.predict(big_patches.reshape((big_patches.shape[0],big_patches.shape[1],big_patches.shape[2],1)))\n",
        "  prop = PROP.predict(big_patches.reshape((big_patches.shape[0],big_patches.shape[1],big_patches.shape[2],1)))\n",
        "  \n",
        "  nx,ny = y.shape[0] // 16 , y.shape[1] // 16\n",
        "\n",
        "  mse[mse > 255] = 255\n",
        "  mse[mse < 0] = 0\n",
        "  jpeg[jpeg > 255] = 255\n",
        "  jpeg[jpeg < 0] = 0\n",
        "  prop[prop > 255] = 255\n",
        "  prop[prop < 0] = 0\n",
        "  mse = np.uint16(mse).reshape((nx,ny,16,16))\n",
        "  jpeg = np.uint16(jpeg).reshape((nx,ny,16,16))\n",
        "  prop = np.uint16(prop).reshape((nx,ny,16,16))\n",
        "\n",
        "  reconstruct_mse = np.zeros((nx*16,ny*16))\n",
        "  reconstruct_jpeg = np.zeros((nx*16,ny*16))\n",
        "  reconstruct_prop = np.zeros((nx*16,ny*16))\n",
        "\n",
        "  for i in range(nx):\n",
        "    for j in range(ny):\n",
        "      reconstruct_mse[i*16:i*16 + 16,j*16:j*16+16] = mse[i][j]\n",
        "      reconstruct_jpeg[i*16:i*16 + 16,j*16:j*16+16] = jpeg[i][j]\n",
        "      reconstruct_prop[i*16:i*16 + 16,j*16:j*16+16] = prop[i][j]\n",
        "\n",
        "\n",
        "  reconstruct_mse[reconstruct_mse > 255] = 255\n",
        "  reconstruct_jpeg[reconstruct_jpeg > 255] = 255\n",
        "  reconstruct_prop[reconstruct_prop > 255] = 255\n",
        "\n",
        "  cv2.imwrite('{}/{}_GT.bmp'.format(version,n),y[:nx*16,:ny*16])\n",
        "  cv2.imwrite('{}/{}_MSE.bmp'.format(version,n),reconstruct_mse)\n",
        "  cv2.imwrite('{}/{}_JPEG.bmp'.format(version,n),reconstruct_jpeg)\n",
        "  cv2.imwrite('{}/{}_PROP.bmp'.format(version,n),reconstruct_prop)\n",
        "  print(f'{n} is saved.')\n",
        "\n",
        "  # plt.figure(figsize=(16,9))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cim5.bmp is saved.\tcim3.bmp is saved.\tcim1.bmp is saved.\tcim15.bmp is saved.\tcim9.bmp is saved.\tcim2.bmp is saved.\tcim10.bmp is saved.\tcim16.bmp is saved.\tcim6.bmp is saved.\tcim7.bmp is saved.\tcim17.bmp is saved.\tcim4.bmp is saved.\tcim8.bmp is saved.\tcim11.bmp is saved.\tcim20.bmp is saved.\tcim14.bmp is saved.\tcim18.bmp is saved.\tcim12.bmp is saved.\tcim13.bmp is saved.\tcim19.bmp is saved.\t"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIHW5Zm2CkHg",
        "outputId": "7d75a6b1-9d2e-4e34-b049-a1e9d63aa72c"
      },
      "source": [
        "!zip -r '6.zip' '6'"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: 6/ (stored 0%)\n",
            "  adding: 6/cim13.bmp_GT.bmp (deflated 64%)\n",
            "  adding: 6/cim6.bmp_JPEG.bmp (deflated 32%)\n",
            "  adding: 6/cim5.bmp_PROP.bmp (deflated 42%)\n",
            "  adding: 6/cim9.bmp_PROP.bmp (deflated 29%)\n",
            "  adding: 6/cim3.bmp_JPEG.bmp (deflated 44%)\n",
            "  adding: 6/cim3.bmp_GT.bmp (deflated 76%)\n",
            "  adding: 6/cim12.bmp_JPEG.bmp (deflated 20%)\n",
            "  adding: 6/cim15.bmp_PROP.bmp (deflated 47%)\n",
            "  adding: 6/cim18.bmp_JPEG.bmp (deflated 20%)\n",
            "  adding: 6/cim15.bmp_MSE.bmp (deflated 48%)\n",
            "  adding: 6/cim13.bmp_MSE.bmp (deflated 40%)\n",
            "  adding: 6/cim19.bmp_PROP.bmp (deflated 22%)\n",
            "  adding: 6/cim3.bmp_PROP.bmp (deflated 45%)\n",
            "  adding: 6/cim4.bmp_PROP.bmp (deflated 42%)\n",
            "  adding: 6/cim2.bmp_GT.bmp (deflated 85%)\n",
            "  adding: 6/cim16.bmp_GT.bmp (deflated 69%)\n",
            "  adding: 6/cim7.bmp_PROP.bmp (deflated 61%)\n",
            "  adding: 6/cim1.bmp_GT.bmp (deflated 71%)\n",
            "  adding: 6/cim3.bmp_MSE.bmp (deflated 46%)\n",
            "  adding: 6/cim14.bmp_PROP.bmp (deflated 42%)\n",
            "  adding: 6/cim1.bmp_JPEG.bmp (deflated 41%)\n",
            "  adding: 6/cim7.bmp_MSE.bmp (deflated 63%)\n",
            "  adding: 6/cim4.bmp_MSE.bmp (deflated 44%)\n",
            "  adding: 6/cim20.bmp_PROP.bmp (deflated 28%)\n",
            "  adding: 6/cim1.bmp_MSE.bmp (deflated 44%)\n",
            "  adding: 6/cim8.bmp_GT.bmp (deflated 71%)\n",
            "  adding: 6/cim11.bmp_JPEG.bmp (deflated 23%)\n",
            "  adding: 6/cim17.bmp_PROP.bmp (deflated 34%)\n",
            "  adding: 6/cim18.bmp_GT.bmp (deflated 37%)\n",
            "  adding: 6/cim19.bmp_GT.bmp (deflated 51%)\n",
            "  adding: 6/cim16.bmp_PROP.bmp (deflated 39%)\n",
            "  adding: 6/cim7.bmp_JPEG.bmp (deflated 61%)\n",
            "  adding: 6/cim16.bmp_JPEG.bmp (deflated 37%)\n",
            "  adding: 6/cim8.bmp_JPEG.bmp (deflated 44%)\n",
            "  adding: 6/cim15.bmp_GT.bmp (deflated 76%)\n",
            "  adding: 6/cim14.bmp_JPEG.bmp (deflated 41%)\n",
            "  adding: 6/cim11.bmp_GT.bmp (deflated 36%)\n",
            "  adding: 6/cim10.bmp_PROP.bmp (deflated 45%)\n",
            "  adding: 6/cim2.bmp_JPEG.bmp (deflated 57%)\n",
            "  adding: 6/cim9.bmp_MSE.bmp (deflated 31%)\n",
            "  adding: 6/cim18.bmp_MSE.bmp (deflated 23%)\n",
            "  adding: 6/cim17.bmp_GT.bmp (deflated 65%)\n",
            "  adding: 6/cim19.bmp_MSE.bmp (deflated 23%)\n",
            "  adding: 6/cim19.bmp_JPEG.bmp (deflated 21%)\n",
            "  adding: 6/cim10.bmp_MSE.bmp (deflated 47%)\n",
            "  adding: 6/cim16.bmp_MSE.bmp (deflated 40%)\n",
            "  adding: 6/cim17.bmp_JPEG.bmp (deflated 32%)\n",
            "  adding: 6/cim5.bmp_GT.bmp (deflated 73%)\n",
            "  adding: 6/cim14.bmp_GT.bmp (deflated 68%)\n",
            "  adding: 6/cim5.bmp_JPEG.bmp (deflated 41%)\n",
            "  adding: 6/cim2.bmp_MSE.bmp (deflated 59%)\n",
            "  adding: 6/cim4.bmp_GT.bmp (deflated 77%)\n",
            "  adding: 6/cim5.bmp_MSE.bmp (deflated 44%)\n",
            "  adding: 6/cim10.bmp_JPEG.bmp (deflated 44%)\n",
            "  adding: 6/cim12.bmp_MSE.bmp (deflated 23%)\n",
            "  adding: 6/cim15.bmp_JPEG.bmp (deflated 45%)\n",
            "  adding: 6/cim20.bmp_MSE.bmp (deflated 31%)\n",
            "  adding: 6/cim7.bmp_GT.bmp (deflated 87%)\n",
            "  adding: 6/cim20.bmp_JPEG.bmp (deflated 27%)\n",
            "  adding: 6/cim12.bmp_PROP.bmp (deflated 22%)\n",
            "  adding: 6/cim6.bmp_GT.bmp (deflated 57%)\n",
            "  adding: 6/cim6.bmp_PROP.bmp (deflated 33%)\n",
            "  adding: 6/cim10.bmp_GT.bmp (deflated 81%)\n",
            "  adding: 6/cim13.bmp_PROP.bmp (deflated 38%)\n",
            "  adding: 6/cim14.bmp_MSE.bmp (deflated 43%)\n",
            "  adding: 6/cim8.bmp_PROP.bmp (deflated 45%)\n",
            "  adding: 6/cim1.bmp_PROP.bmp (deflated 42%)\n",
            "  adding: 6/cim8.bmp_MSE.bmp (deflated 47%)\n",
            "  adding: 6/cim6.bmp_MSE.bmp (deflated 34%)\n",
            "  adding: 6/cim9.bmp_JPEG.bmp (deflated 28%)\n",
            "  adding: 6/cim11.bmp_MSE.bmp (deflated 27%)\n",
            "  adding: 6/cim18.bmp_PROP.bmp (deflated 21%)\n",
            "  adding: 6/cim9.bmp_GT.bmp (deflated 40%)\n",
            "  adding: 6/cim2.bmp_PROP.bmp (deflated 58%)\n",
            "  adding: 6/cim20.bmp_GT.bmp (deflated 40%)\n",
            "  adding: 6/cim4.bmp_JPEG.bmp (deflated 41%)\n",
            "  adding: 6/cim12.bmp_GT.bmp (deflated 60%)\n",
            "  adding: 6/cim17.bmp_MSE.bmp (deflated 36%)\n",
            "  adding: 6/cim13.bmp_JPEG.bmp (deflated 37%)\n",
            "  adding: 6/cim11.bmp_PROP.bmp (deflated 25%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4Wba0lfDSCF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}